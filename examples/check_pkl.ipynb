{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/assist2009/train_valid_sequences_greed_1.csv_0_1_2_3_4.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qseqs': tensor([[ 2471,  1402,  5275,  ...,    -1,    -1,    -1],\n",
       "         [ 4450,  3598, 11922,  ...,  3061,  6790,  7310],\n",
       "         [ 1599, 11925,  8889,  ..., 16954, 16955,  3300],\n",
       "         ...,\n",
       "         [17717, 12868,  5243,  ...,    -1,    -1,    -1],\n",
       "         [ 8333,  9079, 11361,  ..., 14637, 14128, 14394],\n",
       "         [14398, 14411, 14420,  ...,    -1,    -1,    -1]], device='cuda:0'),\n",
       " 'cseqs': tensor([[  5,   5,   2,  ...,  -1,  -1,  -1],\n",
       "         [  5,   5,   5,  ...,   5,   5,   5],\n",
       "         [  5,  12,  12,  ...,   5,  90,  12],\n",
       "         ...,\n",
       "         [114,   5,   5,  ...,  -1,  -1,  -1],\n",
       "         [  0,   0,   0,  ...,  71,  71,  71],\n",
       "         [ 71,  71,  71,  ...,  -1,  -1,  -1]], device='cuda:0'),\n",
       " 'rseqs': tensor([[ 1.,  1.,  1.,  ..., -1., -1., -1.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  ...,  0.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  1.,  0.,  ..., -1., -1., -1.],\n",
       "         [ 1.,  1.,  0.,  ...,  1.,  1.,  0.],\n",
       "         [ 1.,  1.,  0.,  ..., -1., -1., -1.]], device='cuda:0'),\n",
       " 'tseqs': tensor([], device='cuda:0', dtype=torch.int64),\n",
       " 'utseqs': tensor([], device='cuda:0', dtype=torch.int64),\n",
       " 'smasks': tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ..., False, False, False]], device='cuda:0'),\n",
       " 'masks': tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ..., False, False, False]], device='cuda:0')}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/assist2009/train_valid_sequences_greed_1.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,0,0,0,0,0,0,0,0,1,1,1,1,1,16,16,16,16,16,16,16,16,16,16,17,17,17,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,3,11,11,11,11,11,11,11,11,11,11,11,11,11,11,58,58,60,53,60,53,60,52,60,52,60,54,60,54,44,45,44,53,44,45,44,45,11,11,11,12,12,12,12,12,12,20,20,20,20,20,16,16,16,17,17,17,17,17,17,17,17,17,17,3,3,48,48,48,48,48,48,48,48,48,48,48,48,48,49,49,49,49,48,48,48,48,48,48,57,57,28,28,28,28,28,20,20,15,20,31,15,15,48,57,57,57,51,57,57,49,71,92,93,94,95,92,93,94,95,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[31][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,0,0,0,0,0,0,0,0,1,1,1,1,1,16,16,16,16,16,16,16,16,16,16,17,17,17,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,3,11,11,11,11,11,11,11,11,11,11,11,11,11,11,58,58,60,53,60,53,60,52,60,52,60,54,60,54,44,45,44,53,44,45,44,45,11,11,11,12,12,12,12,12,12,20,20,20,20,20,16,16,16,17,17,17,17,17,17,17,17,17,17,3,3,48,48,48,48,48,48,48,48,48,48,48,48,48,49,49,49,49,48,48,48,48,48,48,57,57,28,28,28,28,28,20,20,15,20,31,15,15,48,57,57,57,51,57,57,49,71,92,93,94,95,92,93,94,95,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[31][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "# if torch.cuda.is_available():\n",
    "#     from torch.cuda import FloatTensor, LongTensor\n",
    "# else:\n",
    "# from torch import FloatTensor, LongTensor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "# if torch.cuda.is_available():\n",
    "#     from torch.cuda import FloatTensor, LongTensor\n",
    "# else:\n",
    "#     from torch import FloatTensor, LongTensor\n",
    "\n",
    "class KTDataset(Dataset):\n",
    "    \"\"\"Dataset for KT\n",
    "        can use to init dataset for: (for models except dkt_forget)\n",
    "            train data, valid data\n",
    "            common test data(concept level evaluation), real educational scenario test data(question level evaluation).\n",
    "    Args:\n",
    "        file_path (str): train_valid/test file path\n",
    "        input_type (list[str]): the input type of the dataset, values are in [\"questions\", \"concepts\"]\n",
    "        folds (set(int)): the folds used to generate dataset, -1 for test data\n",
    "        qtest (bool, optional): is question evaluation or not. Defaults to False.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path, input_type, folds, qtest=False, train_ratio=1.0):\n",
    "        super(KTDataset, self).__init__()\n",
    "        self.dori = pd.read_pickle('../data/assist2009/train_valid_sequences_greed_1.csv_0_1_2_3_4.pkl')\n",
    "        for key in self.dori:\n",
    "            self.dori[key] = self.dori[key]#[:100]\n",
    "        print(f\"file path: {file_path}, qlen: {len(self.dori['qseqs'])}, clen: {len(self.dori['cseqs'])}, rlen: {len(self.dori['rseqs'])}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return the dataset length\n",
    "        Returns:\n",
    "            int: the length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.dori[\"rseqs\"])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): the index of the data want to get\n",
    "        Returns:\n",
    "            (tuple): tuple containing:\n",
    "            \n",
    "            - **q_seqs (torch.tensor)**: question id sequence of the 0~seqlen-2 interactions\n",
    "            - **c_seqs (torch.tensor)**: knowledge concept id sequence of the 0~seqlen-2 interactions\n",
    "            - **r_seqs (torch.tensor)**: response id sequence of the 0~seqlen-2 interactions\n",
    "            - **qshft_seqs (torch.tensor)**: question id sequence of the 1~seqlen-1 interactions\n",
    "            - **cshft_seqs (torch.tensor)**: knowledge concept id sequence of the 1~seqlen-1 interactions\n",
    "            - **rshft_seqs (torch.tensor)**: response id sequence of the 1~seqlen-1 interactions\n",
    "            - **mask_seqs (torch.tensor)**: masked value sequence, shape is seqlen-1\n",
    "            - **select_masks (torch.tensor)**: is select to calculate the performance or not, 0 is not selected, 1 is selected, only available for 1~seqlen-1, shape is seqlen-1\n",
    "            - **dcur (dict)**: used only self.qtest is True, for question level evaluation\n",
    "        \"\"\"\n",
    "        dcur = dict()\n",
    "        mseqs = self.dori[\"masks\"][index]\n",
    "        for key in self.dori:\n",
    "            if key in [\"masks\", \"smasks\"]:\n",
    "                continue\n",
    "            if len(self.dori[key]) == 0:\n",
    "                dcur[key] = self.dori[key]\n",
    "                dcur[\"shft_\"+key] = self.dori[key]\n",
    "                continue\n",
    "            # print(f\"key: {key}, len: {len(self.dori[key])}\")\n",
    "            seqs = self.dori[key][index][:-1] * mseqs\n",
    "            shft_seqs = self.dori[key][index][1:] * mseqs\n",
    "            dcur[key] = seqs\n",
    "            dcur[\"shft_\"+key] = shft_seqs\n",
    "        dcur[\"masks\"] = mseqs\n",
    "        dcur[\"smasks\"] = self.dori[\"smasks\"][index]\n",
    "        # print(\"tseqs\", dcur[\"tseqs\"])\n",
    "        return dcur\n",
    "\n",
    "    def __load_data__(self, sequence_path, folds, pad_val=-1,train_ratio=1.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sequence_path (str): file path of the sequences\n",
    "            folds (list[int]): \n",
    "            pad_val (int, optional): pad value. Defaults to -1.\n",
    "        Returns: \n",
    "            (tuple): tuple containing\n",
    "            - **q_seqs (torch.tensor)**: question id sequence of the 0~seqlen-1 interactions\n",
    "            - **c_seqs (torch.tensor)**: knowledge concept id sequence of the 0~seqlen-1 interactions\n",
    "            - **r_seqs (torch.tensor)**: response id sequence of the 0~seqlen-1 interactions\n",
    "            - **mask_seqs (torch.tensor)**: masked value sequence, shape is seqlen-1\n",
    "            - **select_masks (torch.tensor)**: is select to calculate the performance or not, 0 is not selected, 1 is selected, only available for 1~seqlen-1, shape is seqlen-1\n",
    "            - **dqtest (dict)**: not null only self.qtest is True, for question level evaluation\n",
    "        \"\"\"\n",
    "        dori = {\"qseqs\": [], \"cseqs\": [], \"rseqs\": [], \"tseqs\": [], \"utseqs\": [], \"smasks\": []}\n",
    "\n",
    "        # seq_qids, seq_cids, seq_rights, seq_mask = [], [], [], []\n",
    "        df = pd.read_csv(sequence_path)#[0:1000]\n",
    "        df = df[df[\"fold\"].isin(folds)]\n",
    "        interaction_num = 0\n",
    "        # seq_qidxs, seq_rests = [], []\n",
    "        for i, row in df.iterrows():\n",
    "            #use kc_id or question_id as input\n",
    "            if \"concepts\" in self.input_type:\n",
    "                dori[\"cseqs\"].append([int(_) for _ in row[\"concepts\"].split(\",\")])\n",
    "            if \"questions\" in self.input_type:\n",
    "                dori[\"qseqs\"].append([int(_) for _ in row[\"questions\"].split(\",\")])\n",
    "            if \"timestamps\" in row:\n",
    "                dori[\"tseqs\"].append([int(_) for _ in row[\"timestamps\"].split(\",\")])\n",
    "            if \"usetimes\" in row:\n",
    "                dori[\"utseqs\"].append([int(_) for _ in row[\"usetimes\"].split(\",\")])\n",
    "                \n",
    "            dori[\"rseqs\"].append([int(_) for _ in row[\"responses\"].split(\",\")])\n",
    "            dori[\"smasks\"].append([int(_) for _ in row[\"selectmasks\"].split(\",\")])\n",
    "\n",
    "            interaction_num += dori[\"smasks\"][-1].count(1)\n",
    "\n",
    "        for key in dori:\n",
    "            if key not in [\"rseqs\"]:#in [\"smasks\", \"tseqs\"]:\n",
    "                dori[key] = LongTensor(dori[key])\n",
    "            else:\n",
    "                dori[key] = FloatTensor(dori[key])\n",
    "        # print(f\"dori:{dori}\")\n",
    "\n",
    "        mask_seqs = (dori[\"cseqs\"][:,:-1] != pad_val) * (dori[\"cseqs\"][:,1:] != pad_val)\n",
    "        dori[\"masks\"] = mask_seqs\n",
    "\n",
    "        dori[\"smasks\"] = (dori[\"smasks\"][:, 1:] != pad_val)\n",
    "        print(f\"interaction_num: {interaction_num}\")\n",
    "        # print(\"load data tseqs: \", dori[\"tseqs\"])\n",
    "        return dori\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path: kdal, qlen: 32, clen: 32, rlen: 32\n"
     ]
    }
   ],
   "source": [
    "curtrain = KTDataset(\n",
    "            \"kdal\", \"qid\", 1 , train_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KTDataset' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(curtrain\u001b[39m.\u001b[39;49mdata)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KTDataset' object has no attribute 'data'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(curtrain, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "for j, data in enumerate(train_loader):\n",
    "    dcur = data\n",
    "    q, c, r, t = dcur[\"qseqs\"].to(device), dcur[\"cseqs\"].to(device), dcur[\"rseqs\"].to(device), dcur[\"tseqs\"].to(device)\n",
    "    qshft, cshft, rshft, tshft = dcur[\"shft_qseqs\"].to(device), dcur[\"shft_cseqs\"].to(device), dcur[\"shft_rseqs\"].to(device), dcur[\"shft_tseqs\"].to(device)\n",
    "    m, sm = dcur[\"masks\"].to(device), dcur[\"smasks\"].to(device)\n",
    "\n",
    "    ys, preloss = [], []\n",
    "    cq = torch.cat((q[:,0:1], qshft), dim=1)\n",
    "    cc = torch.cat((c[:,0:1], cshft), dim=1)\n",
    "    cr = torch.cat((r[:,0:1], rshft), dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1, 16, 16, 16, 16,\n",
       "        16, 16, 16, 16, 16, 16, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "        16, 16, 17, 17, 17, 17,  3, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 58, 58, 60, 53, 60, 53, 60, 52, 60, 52, 60, 54, 60, 54, 44,\n",
       "        45, 44, 53, 44, 45, 44, 45, 11, 11, 11, 12, 12, 12, 12, 12, 12, 20, 20,\n",
       "        20, 20, 20, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,  3,  3,\n",
       "        48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 48,\n",
       "        48, 48, 48, 48, 48, 57, 57, 28, 28, 28, 28, 28, 20, 20, 15, 20, 31, 15,\n",
       "        15, 48, 57, 57, 57, 51, 57, 57, 49, 71, 92, 93, 94, 95, 92, 93, 94, 95,\n",
       "        71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71,\n",
       "        71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71,\n",
       "        71, 71], device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48, 48, 50, 58, 58, 59, 61, 61, 61, 61, 61, 61, 61, 61, 61, 15, 61, 15,\n",
       "        61, 15, 61, 15, 61, 15, 61, 15, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62,\n",
       "        62, 62, 62, 62, 62, 62, 62, 62, 64, 62, 62, 62, 62, 62, 62, 62, 63, 63,\n",
       "        63, 63, 63, 63, 63, 63, 63, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62,\n",
       "        62, 62, 62, 62, 65, 66, 66, 62, 67, 68, 67, 68, 67, 68, 67, 68, 67, 68,\n",
       "        67, 68, 67, 68, 67, 68, 67, 68, 67, 68, 56, 67, 68, 55, 56, 55, 56, 55,\n",
       "        56, 55, 56, 55, 56, 55, 56, 56, 69, 70, 70, 70, 70, 55, 56, 55, 56, 55,\n",
       "        56, 55, 56, 55, 56, 55, 56, 62, 62, 62, 62, 71, 71, 71, 55, 56, 55, 56,\n",
       "        55, 56, 48, 48, 48, 48, 48, 49, 48, 49, 48, 49, 48, 49, 48, 49, 48, 49,\n",
       "        48, 69, 69, 69, 69, 69, 69, 72, 73, 73, 73, 73, 73, 48, 48, 48, 48, 48,\n",
       "        48, 49, 48, 49, 48, 49, 48, 49, 48, 49, 48, 57, 57, 57, 57, 57, 57, 51,\n",
       "        57, 51], device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zion_kt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "caca5f5d50a7c3693f0c952699a7c4c9f1ed4a006a14fe43e884ab687f0ae607"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
