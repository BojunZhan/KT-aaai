{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab97bc3-eae4-4e00-a11f-ddb00c04203c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c54961-9213-478f-87d0-dd817b3084f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 整合数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "272fd75c-5144-4013-ab15-c557d9a8f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = [\"assist2009\", \"algebra2005\", \"bridge2algebra2006\", \"nips_task34\", \"ednet\", \"peiyou\", \"ednet5w\"]\n",
    "# datasets_dic = {\"assist2009\": 0, \"algebra2005\": 1, \"bridge2algebra2006\": 2, \"nips_task34\": 3, \"ednet\": 4, \"peiyou\": 5, \"ednet5w\": 6}\n",
    "datasets= [ \"ednet_all\"]\n",
    "datasets_dic = {\"ednet_all\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a587ec2-abf4-4a75-b5af-32c7ca1b28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {\"fold\":[], \"uid\":[], \"questions\":[], \"concepts\":[], \"responses\":[], \"dataset\":[], \"timestamps\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c31fbcbe-001f-4636-b07f-409e54e40514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_concepts\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    df_train = pd.read_csv(f\"../data/{dataset}/train_valid_quelevel.csv\")\n",
    "    df_test = pd.read_csv(f\"../data/{dataset}/test_quelevel.csv\")\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    \n",
    "    data_info_ = dict()\n",
    "    with open(f\"../data/{dataset}/keyid2idx.json\", \"r\") as f:\n",
    "        data_info = json.load(f)\n",
    "        for key in data_info:\n",
    "            data_info_.setdefault(key,dict())\n",
    "            try:\n",
    "                for item in data_info[key]:\n",
    "                    data_info_[key][data_info[key][item]] = item\n",
    "            except:\n",
    "                print(f\"{key}\")\n",
    "                continue\n",
    "    for i,row in df.iterrows():\n",
    "        uid = data_info_[\"uid\"][row[\"uid\"]]\n",
    "        uid = uid.replace(\"(\",\"\")\n",
    "        uid = uid.replace(\"\\uFF08\", \"\")\n",
    "        # print(uid)\n",
    "        questions = row[\"questions\"].split(\",\")\n",
    "        # print(f\"questions:{questions}\")\n",
    "        concepts = row[\"concepts\"].split(\",\")\n",
    "        # print(f\"concepts:{concepts}\")\n",
    "        questions = [data_info_[\"questions\"][int(q)] for q in questions]\n",
    "        new_concepts = []\n",
    "        for ccc in concepts:\n",
    "            ccc = ccc.split(\"_\")\n",
    "            concept = [data_info_[\"concepts\"][int(c)] for c in ccc]\n",
    "            concept = \"_\".join(concept)\n",
    "            new_concepts.append(concept)\n",
    "        new_data[\"fold\"].append(row[\"fold\"])\n",
    "        new_data[\"uid\"].append(uid)\n",
    "        new_data[\"questions\"].append(\",\".join(questions))\n",
    "        new_data[\"concepts\"].append(\",\".join(new_concepts))\n",
    "        new_data[\"responses\"].append(row[\"responses\"])\n",
    "        new_data[\"dataset\"].append(dataset)\n",
    "        if \"timestamps\" in row:\n",
    "            new_data[\"timestamps\"].append(row[\"timestamps\"])\n",
    "        else:\n",
    "            new_data[\"timestamps\"].append(\",\".join([str(i) for i in range(len(questions))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd1a2910-aca1-4efe-8284-e14d2919dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e66f02-0ceb-4eef-a843-3c8a613e7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(f\"../data/ednet_all/train_valid_quelevel_pretrain.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce83036-7a79-42bf-a928-1b8aa67468c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea8c4f-cd6f-4701-ba07-882edbdd96ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort = pd.read_csv('../data/ednet_all/train_valid_quelevel_pretrain.csv')\n",
    "df_sort = df_sort.sort_values(by='uid',ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa71f4d-f21a-4c11-a76b-79aea9d61246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d3b1d-b140-4883-a336-6f2f430618c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 完成数据映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f7c257-4566-4b11-bf17-387e46cd4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_mapping_que(df):\n",
    "    id_keys = [\"questions\", \"concepts\", \"uid\"]\n",
    "    dres = dict()\n",
    "    dkeyid2idx = dict()\n",
    "    # print(f\"df.columns: {df.columns}\")\n",
    "    flag = True #判定数据集有没有变化\n",
    "    pre_data = \"ednet\"\n",
    "    for key in df.columns:\n",
    "        if key not in id_keys:\n",
    "            dres[key] = df[key]\n",
    "    for i, row in df.iterrows():\n",
    "        dataset = row[\"dataset\"]\n",
    "        if dataset not in [\"ednet5w\", \"ednet_all\"]:\n",
    "            for j,key in enumerate(id_keys):\n",
    "                if key not in df.columns:\n",
    "                    continue\n",
    "                if key == \"timestamps\":\n",
    "                    dres[key].append(row[key])\n",
    "                else:\n",
    "                    dkeyid2idx.setdefault(key, dict())\n",
    "                    dkeyid2idx[key].setdefault(dataset, dict())\n",
    "                    dres.setdefault(key, [])\n",
    "                    curids = []\n",
    "                    # print(f\"dkeyid2idx:{dkeyid2idx}\")\n",
    "                    # {'questions': {'ednet': {}}}\n",
    "                    for id in row[key].split(\",\"):\n",
    "                        sub_ids = id.split('_')\n",
    "                        sub_curids = []\n",
    "                        for sub_id in sub_ids:\n",
    "                            if sub_id not in dkeyid2idx[key][dataset]:\n",
    "                                if list(dkeyid2idx[key][dataset].values()) == []: #到新的数据集\n",
    "                                    if dataset == \"ednet\":\n",
    "                                        dkeyid2idx[key][dataset][sub_id] = 0\n",
    "                                        flag = False\n",
    "                                    else:\n",
    "                                        # print(f\"key:{key}, dataset:{dataset}, pre_data:{pre_data}\")\n",
    "                                        # print(f\"error:{dkeyid2idx[key][pre_data]}\")\n",
    "                                        dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][pre_data].values())[-1]+1\n",
    "                                else: #原本数据集\n",
    "                                    dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][dataset].values())[-1]+1\n",
    "                                # dkeyid2idx[key][dataset][sub_id] = cnt+1\n",
    "                            sub_curids.append(str(dkeyid2idx[key][dataset][sub_id]))\n",
    "                            # cnt += 1\n",
    "                        curids.append(\"_\".join(sub_curids))\n",
    "                    dres[key].append(\",\".join(curids))\n",
    "            pre_data = dataset\n",
    "        elif dataset == \"ednet5w\":\n",
    "            for j,key in enumerate(id_keys):\n",
    "                if key not in df.columns:\n",
    "                    continue\n",
    "                if key == \"timestamps\":\n",
    "                    dres[key].append(row[key])\n",
    "                else:\n",
    "                    dkeyid2idx.setdefault(key, dict())\n",
    "                    dkeyid2idx[key].setdefault(dataset, dict())\n",
    "                    dres.setdefault(key, [])\n",
    "                    curids = []\n",
    "                    # print(f\"dkeyid2idx:{dkeyid2idx}\")\n",
    "                    # {'questions': {'ednet': {}}}\n",
    "                    for id in row[key].split(\",\"):\n",
    "                        sub_ids = id.split('_')\n",
    "                        sub_curids = []\n",
    "                        for sub_id in sub_ids:\n",
    "                            if sub_id in dkeyid2idx[key][\"ednet\"]:\n",
    "                                sub_curids.append(str(dkeyid2idx[key][\"ednet\"][sub_id]))\n",
    "                            elif sub_id not in dkeyid2idx[key][\"ednet\"] and sub_id not in dkeyid2idx[key][dataset]:\n",
    "                                if list(dkeyid2idx[key][dataset].values()) == []: #到新的数据集\n",
    "                                    dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][\"ednet\"].values())[-1]+1\n",
    "                                else: #原本数据集\n",
    "                                    dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][dataset].values())[-1]+1\n",
    "                                sub_curids.append(str(dkeyid2idx[key][dataset][sub_id]))\n",
    "                            elif sub_id in dkeyid2idx[key][dataset]:\n",
    "                                sub_curids.append(str(dkeyid2idx[key][dataset][sub_id]))\n",
    "                            # cnt += 1\n",
    "                        curids.append(\"_\".join(sub_curids))\n",
    "                    dres[key].append(\",\".join(curids))\n",
    "        else:\n",
    "            for j,key in enumerate(id_keys):\n",
    "                if key not in df.columns:\n",
    "                    continue\n",
    "                if key == \"timestamps\":\n",
    "                    dres[key].append(row[key])\n",
    "                else:\n",
    "                    dkeyid2idx.setdefault(key, dict())\n",
    "                    dkeyid2idx[key].setdefault(dataset, dict())\n",
    "                    dres.setdefault(key, [])\n",
    "                    curids = []\n",
    "                    # print(f\"dkeyid2idx:{dkeyid2idx}\")\n",
    "                    for id in row[key].split(\",\"):\n",
    "                        sub_ids = id.split('_')\n",
    "                        sub_curids = []\n",
    "                        for sub_id in sub_ids:\n",
    "                            if sub_id in dkeyid2idx[key][\"ednet\"]:\n",
    "                                sub_curids.append(str(dkeyid2idx[key][\"ednet\"][sub_id]))\n",
    "                            elif sub_id not in dkeyid2idx[key][\"ednet\"] and sub_id not in dkeyid2idx[key][\"ednet5w\"] and sub_id not in dkeyid2idx[key][dataset]:\n",
    "                                if list(dkeyid2idx[key][dataset].values()) == []: #到新的数据集\n",
    "                                    dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][\"ednet5w\"].values())[-1]+1\n",
    "                                else: #原本数据集\n",
    "                                    dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][dataset].values())[-1]+1\n",
    "                                sub_curids.append(str(dkeyid2idx[key][dataset][sub_id]))\n",
    "                            elif sub_id in dkeyid2idx[key][dataset]:\n",
    "                                sub_curids.append(str(dkeyid2idx[key][dataset][sub_id]))\n",
    "                            # cnt += 1\n",
    "                        curids.append(\"_\".join(sub_curids))\n",
    "                    dres[key].append(\",\".join(curids))\n",
    "    finaldf = pd.DataFrame(dres)\n",
    "    return finaldf, dkeyid2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa8cac",
   "metadata": {},
   "source": [
    "# ednet_all数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5ceca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_mapping_que(df):\n",
    "    id_keys = [\"questions\", \"concepts\", \"uid\"]\n",
    "    dres = dict()\n",
    "    dkeyid2idx = dict()\n",
    "    # print(f\"df.columns: {df.columns}\")\n",
    "    flag = True #判定数据集有没有变化\n",
    "    pre_data = \"ednet_all\"\n",
    "    for key in df.columns:\n",
    "        if key not in id_keys:\n",
    "            dres[key] = df[key]\n",
    "    for i, row in df.iterrows():\n",
    "        dataset = row[\"dataset\"]\n",
    "        if dataset == \"ednet_all\":\n",
    "            for j,key in enumerate(id_keys):\n",
    "                if key not in df.columns:\n",
    "                    continue\n",
    "                if key == \"timestamps\":\n",
    "                    dres[key].append(row[key])\n",
    "                else:\n",
    "                    dkeyid2idx.setdefault(key, dict())\n",
    "                    dkeyid2idx[key].setdefault(dataset, dict())\n",
    "                    dres.setdefault(key, [])\n",
    "                    curids = []\n",
    "                    # print(f\"dkeyid2idx:{dkeyid2idx}\")\n",
    "                    # {'questions': {'ednet': {}}}\n",
    "                    for id in row[key].split(\",\"):\n",
    "                        sub_ids = id.split('_')\n",
    "                        sub_curids = []\n",
    "                        for sub_id in sub_ids:\n",
    "                            if sub_id not in dkeyid2idx[key][dataset]:\n",
    "                                if list(dkeyid2idx[key][dataset].values()) == []: #到新的数据集\n",
    "                                    if dataset == \"ednet_all\":\n",
    "                                        dkeyid2idx[key][dataset][sub_id] = 0\n",
    "                                        flag = False\n",
    "                                    else:\n",
    "                                        # print(f\"key:{key}, dataset:{dataset}, pre_data:{pre_data}\")\n",
    "                                        # print(f\"error:{dkeyid2idx[key][pre_data]}\")\n",
    "                                        dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][pre_data].values())[-1]+1\n",
    "                                else: #原本数据集\n",
    "                                    dkeyid2idx[key][dataset][sub_id] = list(dkeyid2idx[key][dataset].values())[-1]+1\n",
    "                                # dkeyid2idx[key][dataset][sub_id] = cnt+1\n",
    "                            sub_curids.append(str(dkeyid2idx[key][dataset][sub_id]))\n",
    "                            # cnt += 1\n",
    "                        curids.append(\"_\".join(sub_curids))\n",
    "                    dres[key].append(\",\".join(curids))\n",
    "            pre_data = dataset\n",
    "    finaldf = pd.DataFrame(dres)\n",
    "    return finaldf, dkeyid2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2877aff7-9f0b-4313-b693-8659c13e070c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a1646f6c294b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinaldf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdkeyid2idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_mapping_que\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-f2477ac270ff>\u001b[0m in \u001b[0;36mid_mapping_que\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     29\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0msub_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0msub_id\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdkeyid2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                                 \u001b[0;32mif\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdkeyid2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#到新的数据集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                                     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ednet_all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                         \u001b[0mdkeyid2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "finaldf, dkeyid2idx = id_mapping_que (new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46318a2a-fafe-4835-a11e-c5099fc06a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/pretrain/keyid2idx.json\", \"w\") as f:\n",
    "    json.dump(dkeyid2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bb16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/ednet_all/keyid2idx.json\", \"w\") as f:\n",
    "    json.dump(dkeyid2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc9b9c-cdeb-4268-aa2c-39afc8109c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dkeyid2idx['questions']['ednet'].values())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eddf7e-9906-4a2d-bd9d-c8a8edfce816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(dkeyid2idx['questions']['ednet5w'].values()))\n",
    "len(list(dkeyid2idx['questions']['ednet_all'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8793e2-4183-46f4-a401-783bfda64acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(finaldf[\"questions\"]):\n",
    "    row_ = row.split(\",\")\n",
    "    try:\n",
    "        \n",
    "        row_ = [int(x) for x in row_]\n",
    "    except:\n",
    "        print(i,row)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7f015-dc8b-47ff-aced-dc2f41b6d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dkeyid2idx['questions']['bridge2algebra2006'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8295a4be-fc97-4540-bade-7465eaf562c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dkeyid2idx['questions']['algebra2005'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ccf64-ad62-40e7-8eaa-88a9555388e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dkeyid2idx['questions']['ednet_all'].values())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948a628-c6ef-47c9-8d4a-ad2b5fd977eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 计算一题对应最多知识点数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9345805-86b9-46e4-a429-03ecda3f46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_concepts(df):\n",
    "    max_concepts = 1\n",
    "    for i, row in df.iterrows():\n",
    "        cs = row[\"concepts\"].split(\",\")\n",
    "        num_concepts = max([len(c.split(\"_\")) for c in cs])\n",
    "        if num_concepts >= max_concepts:\n",
    "            max_concepts = num_concepts\n",
    "    return max_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34fb41-ca45-4ec1-acf3-3eb68df042f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_concepts = get_max_concepts(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90242d-0b59-422c-8b3f-1db5dd2bf447",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c972c2-6d72-4131-9816-d7e688601990",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 数据统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f6591-9357-406b-bbdd-07d10aaeac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calStatistics(df, stares, key):\n",
    "    allin, allselect = 0, 0\n",
    "    allqs, allcs = set(), set()\n",
    "    for i, row in df.iterrows():\n",
    "        rs = row[\"responses\"].split(\",\")\n",
    "        curlen = len(rs) - rs.count(\"-1\")\n",
    "        allin += curlen\n",
    "        if \"selectmasks\" in row:\n",
    "            ss = row[\"selectmasks\"].split(\",\")\n",
    "            slen = ss.count(\"1\")\n",
    "            allselect += slen\n",
    "        if \"concepts\" in row:\n",
    "            cs = row[\"concepts\"].split(\",\")\n",
    "            fc = list()\n",
    "            for c in cs:\n",
    "                cc = c.split(\"_\")\n",
    "                fc.extend(cc)\n",
    "            curcs = set(fc) - {\"-1\"}\n",
    "            allcs |= curcs\n",
    "        if \"questions\" in row:\n",
    "            qs = row[\"questions\"].split(\",\")\n",
    "            curqs = set(qs) - {\"-1\"}\n",
    "            allqs |= curqs\n",
    "    stares.append(\",\".join([str(s) for s in [key, allin, df.shape[0], allselect]]))\n",
    "    return allin, allselect, len(allqs), len(allcs), df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6877f-27de-4d68-9a30-5703d3e0af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf[finaldf.dataset==\"ednet_all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9834ac-fdff-4aed-854f-010b570db998",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, ss, qs, cs, seqnum = calStatistics(df=finaldf, stares=[], key=\"original train+valid question level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc205a1-600c-4a3a-8f1c-f4d18b9b5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, ss, qs, cs, seqnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e18d69-1d27-49cb-98ec-c95ddbba6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in datasets:\n",
    "    final_sub_df = finaldf[finaldf.dataset==data]\n",
    "    ins_, ss_, qs_, cs_, seqnum_ = calStatistics(df=final_sub_df, stares=[], key=\"original train+valid question level\")\n",
    "    print(f\"dataset:{data}, ins_:{ins_}, ss_:{ss_}, qs_:{qs_}, cs_:{cs_}, seqnum_:{seqnum_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ce1ff-6c9f-4df2-b8a3-ce7658e89c95",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 把数据集划分成sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a5d13b-42c5-4d19-8a0f-73ae74a7184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_sequences(df, effective_keys, min_seq_len=3, maxlen = 200, pad_val = -1):\n",
    "    save_keys = list(effective_keys) + [\"selectmasks\"]\n",
    "    dres = {\"selectmasks\": []}\n",
    "\n",
    "    dropnum = 0\n",
    "    for i, row in df.iterrows():\n",
    "        dcur = save_dcur(row, effective_keys)\n",
    "\n",
    "        rest, lenrs = len(dcur[\"responses\"]), len(dcur[\"responses\"])\n",
    "        j = 0\n",
    "        while lenrs >= j + maxlen:   \n",
    "            rest = rest - (maxlen)\n",
    "            for key in effective_keys:\n",
    "                dres.setdefault(key, [])\n",
    "                if key not in ONE_KEYS:\n",
    "                    dres[key].append(\",\".join(dcur[key][j: j + maxlen]))#[str(k) for k in dcur[key][j: j + maxlen]]))\n",
    "                else:\n",
    "                    dres[key].append(dcur[key])\n",
    "            dres[\"selectmasks\"].append(\",\".join([\"1\"] * maxlen))\n",
    "\n",
    "            j += maxlen\n",
    "        if rest < min_seq_len:# delete sequence len less than min_seq_len\n",
    "            dropnum += rest\n",
    "            continue\n",
    "        \n",
    "        pad_dim = maxlen - rest\n",
    "        for key in effective_keys:\n",
    "            dres.setdefault(key, [])\n",
    "            if key not in ONE_KEYS:\n",
    "                paded_info = np.concatenate([dcur[key][j:], np.array([pad_val] * pad_dim)])\n",
    "                dres[key].append(\",\".join([str(k) for k in paded_info]))\n",
    "            else:\n",
    "                if key == \"dataset\":\n",
    "                    dres[key].append(datasets_dic[dcur[key]])\n",
    "                else:\n",
    "                    dres[key].append(dcur[key])\n",
    "        dres[\"selectmasks\"].append(\",\".join([\"1\"] * rest + [str(pad_val)] * pad_dim))\n",
    "    \n",
    "    # after preprocess data, report\n",
    "    dfinal = dict()\n",
    "    for key in ALL_KEYS:\n",
    "        if key in save_keys:\n",
    "            dfinal[key] = dres[key]\n",
    "    finaldf = pd.DataFrame(dfinal)\n",
    "    print(f\"dropnum: {dropnum}\")\n",
    "    return finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e9ded8-0c8f-44fa-8d8f-69097035d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dcur(row, effective_keys):\n",
    "    dcur = dict()\n",
    "    for key in effective_keys:\n",
    "        if key not in ONE_KEYS:\n",
    "            dcur[key] = row[key].split(\",\")#[int(i) for i in row[key].split(\",\")]\n",
    "        else:\n",
    "            dcur[key] = row[key]\n",
    "    return dcur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ef6f3-aec4-4c10-968e-442a0771f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_KEYS = [\"fold\", \"uid\",\"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ab8d6-cc0b-49ec-868a-61eca83840e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_KEYS = [\"fold\", \"uid\", \"dataset\", \"questions\", \"concepts\", \"responses\", \"timestamps\", \"usetimes\", \"selectmasks\", \"is_repeat\", \"qidxs\", \"rest\", \"orirow\",\"cidxs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2558d9f-3d08-4dc1-8bf3-f5fc3b1fe15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seqs = generate_sequences(df=finaldf, effective_keys={\"uid\", \"dataset\", \"questions\",\"concepts\",\"responses\",\"fold\", \"timestamps\"}, min_seq_len=3, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5660e0-d5d6-46ea-8f50-17089d07b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, ss, qs, cs, seqnum = calStatistics(df=split_seqs, stares=[], key=\"train+valid sequences question level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36250bc1-32cf-4d86-b8d6-77daed7d1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, ss, qs, cs, seqnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b5f58c-7ea2-4e7b-b91c-81e4975f8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, ss, qs, cs, seqnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95e326-70c1-459d-ae09-a4c71ccccdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51c1c9-34e1-4717-87aa-51e61ce7950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24527f68-e274-4e0b-84d1-006c3b231ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acdaf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs = split_seqs\n",
    "test_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs['dataset'] = test_seqs['dataset'].apply(lambda x: datasets_dic[x] if x in datasets_dic else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a9dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656336e8-dc45-458e-8fb5-c97cc34f26a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs.to_csv(f\"../data/ednet_all/train_valid_sequences_quelevel_200.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703b6b0-460c-4da1-a4df-8f510f408237",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv(f\"../data/ednet_all/train_valid_quelevel.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1fe80b-5baf-406a-afcc-7556eb5eec9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 完成测试集映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c31db8-e908-4df6-b8e5-ffca1729acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"assist2009\", \"algebra2005\", \"bridge2algebra2006\", \"nips_task34\", \"ednet\", \"ednet5w\", \"peiyou\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de9131-1ade-4806-8f43-a9e5ac415e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_dataset(datasets):\n",
    "    new_data = {\"fold\":[], \"uid\":[], \"questions\":[], \"concepts\":[], \"responses\":[], \"dataset\":[], \"timestamps\":[]}\n",
    "    for dataset in datasets:\n",
    "        datapath = f\"../data/{dataset}/test_quelevel.csv\"\n",
    "        df = pd.read_csv(datapath)\n",
    "        data_info_ = dict()\n",
    "        with open(f\"../data/{dataset}/keyid2idx.json\") as f:\n",
    "            data_info = json.load(f)\n",
    "            for key in data_info:\n",
    "                data_info_.setdefault(key,dict())\n",
    "                try:\n",
    "                    for item in data_info[key]:\n",
    "                        data_info_[key][data_info[key][item]] = item\n",
    "                except:\n",
    "                    print(f\"{key}\")\n",
    "                    continue\n",
    "        for i,row in df.iterrows():\n",
    "            uid = data_info_[\"uid\"][row[\"uid\"]]\n",
    "            uid = uid.replace(\"(\",\"\")\n",
    "            questions = row[\"questions\"].split(\",\")\n",
    "            # print(f\"questions:{questions}\")\n",
    "            concepts = row[\"concepts\"].split(\",\")\n",
    "            # print(f\"concepts:{concepts}\")\n",
    "            questions = [data_info_[\"questions\"][int(q)] for q in questions]\n",
    "            new_concepts = []\n",
    "            for ccc in concepts:\n",
    "                ccc = ccc.split(\"_\")\n",
    "                concept = [data_info_[\"concepts\"][int(c)] for c in ccc]\n",
    "                concept = \"_\".join(concept)\n",
    "                new_concepts.append(concept)\n",
    "            new_data[\"fold\"].append(row[\"fold\"])\n",
    "            new_data[\"uid\"].append(uid)\n",
    "            new_data[\"questions\"].append(\",\".join(questions))\n",
    "            new_data[\"concepts\"].append(\",\".join(new_concepts))\n",
    "            new_data[\"responses\"].append(row[\"responses\"])\n",
    "            new_data[\"dataset\"].append(dataset)\n",
    "            if \"timestamps\" in row:\n",
    "                new_data[\"timestamps\"].append(row[\"timestamps\"])\n",
    "            else:\n",
    "                new_data[\"timestamps\"].append(\",\".join([str(i) for i in range(len(questions))]))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40106133-1b4c-449d-86b3-89813a449527",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = map_dataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5622ff5-c2b4-4664-8fa4-c7ac1fbaa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9a627-303f-44bf-ac6f-62a8a6631e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2414743-1964-4252-b5e4-377e3ed2a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../data/pretrain/keyid2idx.json\",\"r\") as f:\n",
    "    dkeyid2idx = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec8906-35fa-4243-82b0-4c92cc11958f",
   "metadata": {},
   "source": [
    "## 除ednet5w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = [\"assist2009\", \"algebra2005\", \"bridge2algebra2006\", \"nips_task34\", \"ednet\", \"peiyou\"]\n",
    "datasets = [\"ednet_all\"]\n",
    "for dataset in datasets:\n",
    "    if dataset not in [\"ednet5w\"]:\n",
    "        sub_df = new_df[new_df.dataset==dataset]\n",
    "        new_map_data = {\"fold\":[], \"uid\":[], \"dataset\":[], \"questions\":[], \"concepts\":[], \"responses\":[], \"timestamps\":[]}\n",
    "        for i,row in sub_df.iterrows():\n",
    "            questions = [str(dkeyid2idx[\"questions\"][dataset][x]) for x in row[\"questions\"].split(\",\")]\n",
    "            concepts = row[\"concepts\"].split(\",\")\n",
    "            new_concepts = []\n",
    "            for ccc in concepts:\n",
    "                ccc = ccc.split(\"_\")\n",
    "                concept = [str(dkeyid2idx[\"concepts\"][dataset][c]) for c in ccc]\n",
    "                # concept = [str(dkeyid2idx.get(\"concepts\").get(dataset).get(c,len(dkeyid2idx['concepts'][dataset]))) for c in ccc]\n",
    "                concept = \"_\".join(concept)\n",
    "                new_concepts.append(concept)\n",
    "            new_map_data[\"fold\"].append(row[\"fold\"])\n",
    "            new_map_data[\"uid\"].append(row[\"uid\"])\n",
    "            new_map_data[\"dataset\"].append(dataset)\n",
    "            new_map_data[\"questions\"].append(\",\".join(questions))\n",
    "            new_map_data[\"concepts\"].append(\",\".join(new_concepts))\n",
    "            new_map_data[\"responses\"].append(row[\"responses\"])\n",
    "            new_map_data[\"timestamps\"].append(row[\"timestamps\"])\n",
    "            new_map_df = pd.DataFrame(new_map_data)\n",
    "            new_map_df.to_csv(f\"../data/{dataset}/test_quelevel_pretrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1361f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_map_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22e123-bca3-400c-9c84-0d789bf59247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = [\"assist2009\", \"algebra2005\", \"bridge2algebra2006\", \"nips_task34\", \"ednet\", \"peiyou\"]\n",
    "# for dataset in datasets:\n",
    "#     sub_df = new_df[new_df.dataset==dataset]\n",
    "#     new_map_data = {\"fold\":[], \"uid\":[], \"questions\":[], \"concepts\":[], \"responses\":[], \"timestamps\":[]}\n",
    "#     for i,row in sub_df.iterrows():\n",
    "#         questions = [str(dkeyid2idx[\"questions\"][dataset][x]) for x in row[\"questions\"].split(\",\")]\n",
    "#         concepts = row[\"concepts\"].split(\",\")\n",
    "#         dataset = datasets_dic[dataset]\n",
    "#         new_concepts = []\n",
    "#         for ccc in concepts:\n",
    "#             ccc = ccc.split(\"_\")\n",
    "#             concept = [str(dkeyid2idx[\"concepts\"][dataset][c]) for c in ccc]\n",
    "#             # concept = [str(dkeyid2idx.get(\"concepts\").get(dataset).get(c,len(dkeyid2idx['concepts'][dataset]))) for c in ccc]\n",
    "#             concept = \"_\".join(concept)\n",
    "#             new_concepts.append(concept)\n",
    "#         new_map_data[\"fold\"].append(row[\"fold\"])\n",
    "#         new_map_data[\"uid\"].append(row[\"uid\"])\n",
    "#         new_map_data[\"questions\"].append(\",\".join(questions))\n",
    "#         new_map_data[\"concepts\"].append(\",\".join(new_concepts))\n",
    "#         new_map_data[\"responses\"].append(row[\"responses\"])\n",
    "#         new_map_data[\"timestamps\"].append(row[\"timestamps\"])\n",
    "#         new_map_df = pd.DataFrame(new_map_data)\n",
    "#         new_map_df.to_csv(f\"../data/{dataset}/test_quelevel_pretrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8030dde-a52d-4c32-a03f-4714bb6dfc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"ednet5w\"]\n",
    "for dataset in datasets:\n",
    "    sub_df = new_df[new_df.dataset==dataset]\n",
    "    new_map_data = {\"fold\":[], \"uid\":[], \"dataset\":[], \"questions\":[], \"concepts\":[], \"responses\":[], \"timestamps\":[]}\n",
    "    for i,row in sub_df.iterrows():\n",
    "        questions = []\n",
    "        for x in row[\"questions\"].split(\",\"):\n",
    "            if x in dkeyid2idx[\"questions\"][\"ednet\"]:\n",
    "                questions.append(str(dkeyid2idx[\"questions\"][\"ednet\"][x]))\n",
    "            else:\n",
    "                questions.append(str(dkeyid2idx[\"questions\"][dataset][x]))\n",
    "        \n",
    "        concept = []\n",
    "        concepts = row[\"concepts\"].split(\",\")\n",
    "        new_concepts = []\n",
    "        for ccc in concepts:\n",
    "            ccc = ccc.split(\"_\")\n",
    "            concept = []\n",
    "            for c in ccc:\n",
    "                if c in dkeyid2idx['concepts'][\"ednet\"]:\n",
    "                    concept.append(str(dkeyid2idx[\"concepts\"][\"ednet\"][c]))\n",
    "                else:\n",
    "                    concept.append(str(dkeyid2idx[\"concepts\"][dataset][c]))\n",
    "            concept = \"_\".join(concept)\n",
    "            new_concepts.append(concept)\n",
    "        new_map_data[\"fold\"].append(row[\"fold\"])\n",
    "        new_map_data[\"uid\"].append(row[\"uid\"])\n",
    "        new_map_data[\"dataset\"].append(dataset)\n",
    "        new_map_data[\"questions\"].append(\",\".join(questions))\n",
    "        new_map_data[\"concepts\"].append(\",\".join(new_concepts))\n",
    "        new_map_data[\"responses\"].append(row[\"responses\"])\n",
    "        new_map_data[\"timestamps\"].append(row[\"timestamps\"])\n",
    "        new_map_df = pd.DataFrame(new_map_data)\n",
    "        new_map_df.to_csv(f\"../data/{dataset}/test_quelevel_pretrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04700f11-4f80-497c-a7a5-b8d042d128cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_map_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080999a4-2662-4f8a-8860-08d1bf90df8c",
   "metadata": {},
   "source": [
    "## 生成window测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbce821-f526-494f-af04-8faff2367e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_window_sequences(df, effective_keys, maxlen=200, pad_val=-1):\n",
    "    save_keys = list(effective_keys) + [\"selectmasks\"]\n",
    "    dres = {\"selectmasks\": []}\n",
    "    for i, row in df.iterrows():\n",
    "        dcur = save_dcur(row, effective_keys)\n",
    "        lenrs = len(dcur[\"responses\"])\n",
    "        if lenrs > maxlen:\n",
    "            for key in effective_keys:\n",
    "                dres.setdefault(key, [])\n",
    "                if key not in ONE_KEYS:\n",
    "                    dres[key].append(\",\".join(dcur[key][0: maxlen]))#[str(k) for k in dcur[key][0: maxlen]]))\n",
    "                else:\n",
    "                    dres[key].append(dcur[key])\n",
    "            dres[\"selectmasks\"].append(\",\".join([\"1\"] * maxlen))\n",
    "            for j in range(maxlen+1, lenrs+1):\n",
    "                for key in effective_keys:\n",
    "                    dres.setdefault(key, [])\n",
    "                    if key not in ONE_KEYS:\n",
    "                        dres[key].append(\",\".join([str(k) for k in dcur[key][j-maxlen: j]]))\n",
    "                    else:\n",
    "                        if key == \"dataset\":\n",
    "                            dres[key].append(datasets_dic[dcur[key]])\n",
    "                        else:\n",
    "                            dres[key].append(dcur[key])\n",
    "                dres[\"selectmasks\"].append(\",\".join([str(pad_val)] * (maxlen - 1) + [\"1\"]))\n",
    "        else:\n",
    "            for key in effective_keys:\n",
    "                dres.setdefault(key, [])\n",
    "                if key not in ONE_KEYS:\n",
    "                    pad_dim = maxlen - lenrs\n",
    "                    paded_info = np.concatenate([dcur[key][0:], np.array([pad_val] * pad_dim)])\n",
    "                    dres[key].append(\",\".join([str(k) for k in paded_info]))\n",
    "                else:\n",
    "                    if key == \"dataset\":\n",
    "                        dres[key].append(datasets_dic[dcur[key]])\n",
    "                    else:\n",
    "                        dres[key].append(dcur[key])\n",
    "            dres[\"selectmasks\"].append(\",\".join([\"1\"] * lenrs + [str(pad_val)] * pad_dim))\n",
    "    \n",
    "    dfinal = dict()\n",
    "    for key in ALL_KEYS:\n",
    "        if key in save_keys:\n",
    "            # print(f\"key: {key}, len: {len(dres[key])}\")\n",
    "            dfinal[key] = dres[key]\n",
    "    finaldf = pd.DataFrame(dfinal)\n",
    "    return finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c01706-118a-49c5-acc8-ca9a488827a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"assist2009\", \"algebra2005\", \"bridge2algebra2006\", \"nips_task34\", \"ednet\", \"peiyou\", \"ednet5w\"]\n",
    "for data in datasets:\n",
    "    test_df = pd.read_csv(f\"../data/{data}/test_quelevel_pretrain.csv\")\n",
    "    test_window_seqs = generate_window_sequences(test_df, list({\"uid\",\"dataset\",\"questions\",\"concepts\",\"responses\",\"fold\"}), maxlen=200)\n",
    "    test_window_seqs['dataset'] = test_window_seqs['dataset'].apply(lambda x: datasets_dic[x] if x in datasets_dic else x)\n",
    "    test_window_seqs.to_csv(f\"../data/{data}/test_window_sequences_quelevel_pretrain_200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c1c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"../data/ednet_all/test_quelevel_pretrain.csv\")\n",
    "test_window_seqs = generate_window_sequences(test_df, list({\"uid\",\"dataset\",\"questions\",\"concepts\",\"responses\",\"fold\"}), maxlen=200)\n",
    "test_window_seqs['dataset'] = test_window_seqs['dataset'].apply(lambda x: datasets_dic[x] if x in datasets_dic else x)\n",
    "test_window_seqs.to_csv(f\"../data/ednet_all/test_window_sequences_quelevel_200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9baf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_window_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b0008-b885-493f-9a1d-f3a0e1069bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc5ab0-adde-4582-8fe1-b494797544d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_window_seqs = generate_window_sequences(test_df, list({\"uid\",\"questions\",\"concepts\",\"responses\",\"fold\"}), maxlen=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c646cc0e-b4e4-4d43-b85e-df570ce2507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_window_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fd521-c46d-4840-a01c-e083444b8120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 你的数据\n",
    "data = [229471, 513430, 1463212, 1109911, 462626, 4719979, 4446825]\n",
    "\n",
    "# 数据标签\n",
    "labels = ['229471', '513430', '1463212', '1109911', '462626', '4719979', '4446825']\n",
    "\n",
    "# 创建饼图\n",
    "plt.pie(data, labels = labels, autopct='%1.1f%%')\n",
    "\n",
    "# 添加标题\n",
    "plt.title('数据饼图')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e4009-3a69-484a-94d9-51510453f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 你的数据\n",
    "data = [229471, 513430, 1463212, 1109911, 462626, 4719979, 4446825]\n",
    "\n",
    "# 数据标签\n",
    "labels = [\"AS2009\", \"AL2005\", \"BD2006\", \"NIPS34\", \"EdNet\", \"EdNet5w\", \"Peiyou\"]\n",
    "\n",
    "# 创建饼图\n",
    "plt.pie(data, labels = labels, autopct='%1.1f%%')\n",
    "\n",
    "# 添加标题\n",
    "plt.title('Pretrain data distribution')\n",
    "\n",
    "plt.savefig(\"pie_chart.pdf\", format='pdf')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e1ab8-a47a-4f5f-b88d-5d182fed7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/root/autodl-nas/project/pykt_nips2022/examples/best_model_path/ednet5w/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ecc3b-ca13-4cd9-914f-e309eaa0b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c54f5-04aa-48af-bef6-863ca5457548",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c45346-ddc5-44fa-8ec4-85404687010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model_path = os.listdir(os.path.join(path, model))\n",
    "    for best_path in model_path:\n",
    "        print(\"- \"+os.path.join(path, model, best_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4aa057-8378-4783-bbaa-8e43a087d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取csv文件\n",
    "train=pd.read_csv(\"../data/ednet_all/train_valid_sequences_quelevel_200.csv\")\n",
    "\n",
    "# 检查\"timestamps\"列的每一个元素的长度是否都为200\n",
    "is_all_200 = train['timestamps'].apply(lambda x: len(x.split(\",\")) == 200).all()\n",
    "\n",
    "print(is_all_200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dbe8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
